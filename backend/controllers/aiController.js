import Document from '../models/Document.js';
import Flashcard from '../models/Flashcard.js';
import Quiz from '../models/Quiz.js';
import * as aiService from '../utils/aiService.js';
import { findRelevantChunks } from '../utils/textChunker.js';
import ChatHistory from '../models/ChatHistory.js';

// @desc Generate flashcards from document
// @route POST /api/ai/generate-flashcards
// @access Private
export const generateFlashcards = async (req, res, next) => {
  try {
    const { documentId, count = 10 } = req.body;

    if (!documentId) {
      return res.status(400).json({
        success: false,
        error: 'Please provide documentId',
        statusCode: 400
      });
    }

    const document = await Document.findOne({
      _id: documentId,
      userId: req.user._id,
      status: 'ready'
    });

    if (!document) {
      return res.status(404).json({
        success: false,
        error: 'Document not found or not ready',
        statusCode: 404
      });
    }

    // Check if document has extracted text
    if (!document.extractedText || document.extractedText.trim().length === 0) {
      return res.status(400).json({
        success: false,
        error: 'Document has no extracted text. Please re-upload.',
        statusCode: 400
      });
    }

    // Generate flashcards using local LLM
    const cards = await aiService.generateFlashcards(
      document.extractedText,
      parseInt(count)
    );

    // Save to database
    const flashcardSet = await Flashcard.create({
      userId: req.user._id,
      documentId: document._id,
      cards: cards.map(card => ({
        question: card.question,
        answer: card.answer,
        difficulty: card.difficulty || 'medium',
        reviewCount: 0,
        isStarred: false
      }))
    });

    res.status(201).json({
      success: true,
      data: flashcardSet,
      message: 'Flashcards generated successfully'
    });
  } catch (error) {
    console.error('Flashcards generation error:', error);
    next(error);
  }
};

// @desc Generate quiz from document
// @route POST /api/ai/generate-quiz
// @access Private
export const generateQuiz = async (req, res, next) => {
  try {
    const { documentId, numQuestions = 5, title } = req.body;

    if (!documentId) {
      return res.status(400).json({
        success: false,
        error: 'Please provide documentId',
        statusCode: 400
      });
    }

    const document = await Document.findOne({
      _id: documentId,
      userId: req.user._id,
      status: 'ready'
    });

    if (!document) {
      return res.status(404).json({
        success: false,
        error: 'Document not found or not ready',
        statusCode: 404
      });
    }

    // Check if document has extracted text
    if (!document.extractedText || document.extractedText.trim().length === 0) {
      return res.status(400).json({
        success: false,
        error: 'Document has no extracted text. Please re-upload.',
        statusCode: 400
      });
    }

    // Log document content preview for debugging
    console.log('ðŸ“ Document text preview:', document.extractedText.substring(0, 200) + '...');

    // Generate quiz using local LLM
    let quizData;
    try {
      quizData = await aiService.generateQuiz(
        document.extractedText,
        parseInt(numQuestions)
      );
    } catch (error) {
      console.error('âŒ Ollama quiz generation failed:', error.message);
      return res.status(500).json({
        success: false,
        error: 'Failed to generate quiz with AI model',
        details: error.message
      });
    }

    // Handle different response formats from Ollama
    let questions = [];
    let quizTitle = title || `${document.title} - Quiz`;

    // If aiService returns entire quiz object (with title + questions)
    if (quizData && quizData.questions) {
      questions = quizData.questions;
      quizTitle = quizData.title || quizTitle;
    } 
    // If aiService returns just questions array
    else if (Array.isArray(quizData)) {
      questions = quizData;
    }
    // If it's something else unexpected
    else {
      console.error('âŒ Unexpected quiz data format:', quizData);
      // Create fallback questions
      questions = Array.from({ length: parseInt(numQuestions) }, (_, i) => ({
        question: `Question ${i + 1}`,
        options: ["Option A", "Option B", "Option C", "Option D"],
        correctAnswer: "Option A"
      }));
    }

    // Validate questions
    if (!questions || !Array.isArray(questions) || questions.length === 0) {
      console.error('âŒ No questions generated by AI');
      return res.status(500).json({
        success: false,
        error: 'No questions were generated. Try again with different content.'
      });
    }

    // Log generated questions for debugging
    console.log('ðŸŽ¯ Generated questions count:', questions.length);
    console.log('ðŸŽ¯ First question:', questions[0]?.question || 'No question');

    // Save to database
    const quiz = await Quiz.create({
      userId: req.user._id,
      documentId: document._id,
      title: quizTitle,
      questions: questions.map(q => ({
        question: q.question,
        options: Array.isArray(q.options) ? q.options : [],
        correctAnswer: q.correctAnswer || (q.options?.[0] || ''),
        explanation: q.explanation || '',
        difficulty: q.difficulty || 'medium'
      })),
      totalQuestions: questions.length,
      userAnswers: [],
      score: 0
    });

    res.status(201).json({
      success: true,
      data: quiz,
      message: 'Quiz generated successfully'
    });
  } catch (error) {
    console.error('Quiz generation error:', error);
    next(error);
  }
};

// @desc Generate document summary
// @route POST /api/ai/generate-summary
// @access Private
export const generateSummary = async (req, res, next) => {
  try {
    const { documentId } = req.body;

    if (!documentId) {
      return res.status(400).json({
        success: false,
        error: 'Please provide documentId',
        statusCode: 400
      });
    }

    const document = await Document.findOne({
      _id: documentId,
      userId: req.user._id,
      status: 'ready'
    });

    if (!document) {
      return res.status(404).json({
        success: false,
        error: 'Document not found or not ready',
        statusCode: 404
      });
    }

    // Check if document has extracted text
    if (!document.extractedText || document.extractedText.trim().length === 0) {
      return res.status(400).json({
        success: false,
        error: 'Document has no extracted text. Please re-upload.',
        statusCode: 400
      });
    }

    // Generate summary using local LLM
    const summary = await aiService.generateSummary(document.extractedText);

    res.status(200).json({
      success: true,
      data: {
        documentId: document._id,
        title: document.title,
        summary
      },
      message: 'Summary generated successfully'
    });
  } catch (error) {
    console.error('Summary generation error:', error);
    next(error);
  }
};

// @desc Chat with document
// @route POST /api/ai/chat
// @access Private
export const chat = async (req, res, next) => {
  try {
    const { documentId, question } = req.body;

    if (!documentId || !question) {
      return res.status(400).json({
        success: false,
        error: 'Please provide documentId and question',
        statusCode: 400
      });
    }

    const document = await Document.findOne({
      _id: documentId,
      userId: req.user._id,
      status: 'ready'
    });

    if (!document) {
      return res.status(404).json({
        success: false,
        error: 'Document not found or not ready',
        statusCode: 404
      });
    }

    // âœ… SAFETY CHECK: Ensure chunks exist
    if (!document.chunks || document.chunks.length === 0) {
      return res.status(400).json({
        success: false,
        error: 'Document has no processed content. Please re-upload.',
        statusCode: 400
      });
    }

    // Find relevant chunks
    const relevantChunks = findRelevantChunks(document.chunks, question, 3);
    
    // âœ… SAFETY CHECK: Ensure we found chunks
    if (relevantChunks.length === 0) {
      return res.status(400).json({
        success: false,
        error: 'No relevant content found for your question.',
        statusCode: 400
      });
    }

    const chunkIndices = relevantChunks.map(c => c.chunkIndex);

    // Get or create chat history
    let chatHistory = await ChatHistory.findOne({
      userId: req.user._id,
      documentId: document._id
    });

    if (!chatHistory) {
      chatHistory = await ChatHistory.create({
        userId: req.user._id,
        documentId: document._id,
        messages: []
      });
    }

    // âœ… LOG: Using local LLM (optional but clean)
    console.log('ðŸ” Generating response with local LLM:', {
      question,
      chunkCount: relevantChunks.length,
      firstChunkPreview: relevantChunks[0].content.substring(0, 100) + '...'
    });

    // Generate response using local LLM
    const answer = await aiService.chatWithContext(question, relevantChunks);

    // Save conversation
    chatHistory.messages.push(
      {
        role: 'user',
        content: question,
        timestamp: new Date(),
        relevantChunks: []
      },
      {
        role: 'assistant',
        content: answer,
        timestamp: new Date(),
        relevantChunks: chunkIndices
      }
    );

    await chatHistory.save();

    res.status(200).json({
      success: true,
      data: {
        question,
        answer,
        relevantChunks: chunkIndices,
        chatHistory: chatHistory._id
      },
      message: 'Response generated successfully'
    });
  } catch (error) {
    console.error('ðŸ’¥ Chat controller error:', error.message);
    console.error('Stack:', error.stack);
    next(error);
  }
};

// @desc Explain concept from document
// @route POST /api/ai/explain-concept
// @access Private
export const explainConcept = async (req, res, next) => {
  try {
    const { documentId, concept } = req.body;

    if (!documentId || !concept) {
      return res.status(400).json({
        success: false,
        error: 'Please provide documentId and concept',
        statusCode: 400
      });
    }

    const document = await Document.findOne({
      _id: documentId,
      userId: req.user._id,
      status: 'ready'
    });

    if (!document) {
      return res.status(404).json({
        success: false,
        error: 'Document not found or not ready',
        statusCode: 404
      });
    }

    // Find relevant chunks for the concept
    const relevantChunks = findRelevantChunks(document.chunks, concept, 3);
    const context = relevantChunks.map(c => c.content).join('\n\n');

    // Generate explanation using local LLM
    const explanation = await aiService.explainConcept(concept, context);

    res.status(200).json({
      success: true,
      data: {
        concept,
        explanation,
        relevantChunks: relevantChunks.map(c => c.chunkIndex)
      },
      message: 'Explanation generated successfully'
    });
  } catch (error) {
    console.error('Explain concept error:', error);
    next(error);
  }
};

// @desc Get chat history for a document
// @route GET /api/ai/chat-history/:documentId
// @access Private
export const getChatHistory = async (req, res, next) => {
  try {
    const { documentId } = req.params;

    if (!documentId) {
      return res.status(400).json({
        success: false,
        error: 'Please provide documentId',
        statusCode: 400
      });
    }

    const chatHistory = await ChatHistory.findOne({
      userId: req.user._id,
      documentId: documentId
    }).select('messages');

    if (!chatHistory) {
      return res.status(200).json({
        success: true,
        data: [],
        message: 'No chat history found for this document'
      });
    }

    res.status(200).json({
      success: true,
      data: chatHistory.messages,
      message: 'Chat history retrieved successfully'
    });
  } catch (error) {
    console.error('Get chat history error:', error);
    next(error);
  }
};